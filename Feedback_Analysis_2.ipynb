{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import sklearn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Classifier 1](#Classifier-1) <br>\n",
    "[Classifier 2](#Classifier-2) <br>\n",
    "[Classifier 3](#Classifier-3) <br>\n",
    "[Classifier 3 Holdout Group/Cross-Val](#Classifier-3-Holdout-Group-Cross-Val) <br>\n",
    "[Classifier 4](#Classifier-4) <br>\n",
    "[Classifier 5](#Classifier-5) <br>\n",
    "[Holdout Groups](#Holdout-Groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = pd.read_table(\"imdb_labelled.txt\", sep = '\\t', names = ['Review', 'Rating'])\n",
    "amazon = pd.read_table(\"amazon_cells_labelled.txt\", sep = '\\t', names = ['Review', 'Rating'])\n",
    "yelp = pd.read_table(\"yelp_labelled.txt\", sep = '\\t', names = ['Review', 'Rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Classifier-1\"></a>\n",
    "### [Classifier 1](#Classifier-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating the keyword lists:\n",
    "\n",
    "positive_keywords = ['love', 'liked', 'best', 'great', 'incredible', 'beautiful', 'cool', 'wonderful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Applying those lists to the text of the reviews:\n",
    "\n",
    "for key in positive_keywords:\n",
    "    text[str(key)] = text.Review.str.contains(\n",
    "    ' ' + str(key) + ' ',\n",
    "        case = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Changing the Rating column so it contains boolean values:\n",
    "\n",
    "text['Rating'] = (text['Rating'] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting the data and target columns:\n",
    "\n",
    "data = text[positive_keywords]\n",
    "target = text['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total columns: 748.  Number of mislabeled columns: 329\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "bnb.fit(data, target)\n",
    "\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "print(\"Number of total columns: {}.  Number of mislabeled columns: {}\".format(\n",
    "        data.shape[0],\n",
    "        (target != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TN = ((text['Rating'] == False) & (y_pred == False)).sum()\n",
    "FP = ((text['Rating'] == False) & (y_pred == True)).sum()\n",
    "TP = ((text['Rating'] == True) & (y_pred == True)).sum()\n",
    "FN = ((text['Rating'] == True) & (y_pred == False)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[350, 12], [317, 69]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = [[TN, FP],\n",
    "           [FN, TP]]\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[350,  12],\n",
       "       [317,  69]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(target, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Sensitivity is 17.88%. The Specificity is 96.69%.\n"
     ]
    }
   ],
   "source": [
    "# Percentage of positives correctly identified:\n",
    "sensitivity = (TP/(FN+TP))\n",
    "\n",
    "# Percentage of negatives correctly identified:\n",
    "specificity = (TN/(TN+FP))\n",
    "\n",
    "print(\"The Sensitivity is {:.2%}. The Specificity is {:.2%}.\".format(sensitivity, specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     386\n",
       "False    362\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = data[:74]\n",
    "X_test2 = data[75:150]\n",
    "X_train = data[75:]\n",
    "X_train2 = pd.concat([X_test, data[151:]])\n",
    "\n",
    "y_test = target[:74]\n",
    "y_test2 = target[75:150]\n",
    "y_train = target[75:]\n",
    "y_train2 = pd.concat([y_test, target[151:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5499254843517138"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.score(X_train2, y_train2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22666666666666666"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.score(X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 20% Holdout: 0.5733333333333334\n",
      "Testing on Sample: 0.5601604278074866\n"
     ]
    }
   ],
   "source": [
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.56578947, 0.54666667, 0.53333333, 0.56      ,\n",
       "       0.54666667, 0.66216216, 0.54054054, 0.58108108, 0.54054054])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(bnb, data, target, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This classifier was biased towards negative labeling.  Given that the list of positive terms was so short, the classifer would classify anything not containing those words as negative, even though they were positive.  As a result, the false negatives were overly prevalent, while the negative columns were well predicted.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a = id = \"Classifier-2\"></a>\n",
    "### [Classifier 2](#Classifier-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negative_keywords = ['terrible', 'hated', 'bad', 'too', 'awful', 'slow', 'bore', 'boring']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key in negative_keywords:\n",
    "    text[str(key)] = text.Review.str.contains(\n",
    "    ' ' + str(key) + ' ',\n",
    "        case = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = text[negative_keywords]\n",
    "text['bad_rating'] = (text['Rating'] == False)\n",
    "target = text.bad_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bnb = BernoulliNB()\n",
    "\n",
    "bnb.fit(data, target)\n",
    "\n",
    "y_pred = bnb.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total columns: 748.  Number of mislabeled columns: 321\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of total columns: {}.  Number of mislabeled columns: {}\".format(\n",
    "        data.shape[0],\n",
    "        (target != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[48, 314], [7, 379]]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TN = ((target == True) & (y_pred == True)).sum()\n",
    "FP = ((target == True) & (y_pred == False)).sum()\n",
    "FN = ((target == False) & (y_pred == True)).sum()\n",
    "TP = ((target == False) & (y_pred == False)).sum()\n",
    "\n",
    "matrix = [[TN, FP],\n",
    "           [FN, TP]]\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[379,   7],\n",
       "       [314,  48]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(target, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Sensitivity is 98.19%. The Specificity is 13.26%.\n"
     ]
    }
   ],
   "source": [
    "# Percentage of positives correctly identified:\n",
    "sensitivity = (TP/(FN+TP))\n",
    "\n",
    "# Percentage of negatives correctly identified:\n",
    "specificity = (TN/(TN+FP))\n",
    "\n",
    "print(\"The Sensitivity is {:.2%}. The Specificity is {:.2%}.\".format(sensitivity, specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twenty Percent Holdout Score:0.4866666666666667\n"
     ]
    }
   ],
   "source": [
    "# Holdout Testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size = .2)\n",
    "print('Twenty Percent Holdout Score:' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52631579, 0.56578947, 0.56      , 0.6       , 0.6       ,\n",
       "       0.57333333, 0.55405405, 0.58108108, 0.52702703, 0.59459459])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-Valuation Testing:\n",
    "cross_val_score(bnb, data, target, cv = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was trying out the negative list, which correctly identified 8 more inputs than the last classifier.  The Sensitivity and Specificity also switched...which means that we are identifying more positive ratings correctly, but our negative identifiers have lost their accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Classifier-3\"></a>\n",
    "### [Classifier 3](#Classifier-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_keywords = ['love', 'liked', 'best', 'great', 'incredible', 'beautiful', 'cool', 'wonderful']\n",
    "negative_keywords = ['terrible', 'hated', 'bad', 'too', 'awful', 'slow', 'bore', 'boring']\n",
    "\n",
    "for key in positive_keywords:\n",
    "    text[str(key)] = text.Review.str.contains(\n",
    "    ' ' + str(key) + ' ',\n",
    "        case = False)\n",
    "    \n",
    "for key in negative_keywords:\n",
    "    text[str(key)] = text.Review.str.contains(\n",
    "    ' ' + str(key) + ' ',\n",
    "        case = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = text[negative_keywords + positive_keywords]\n",
    "target = text['Rating'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bnb.fit(data, target)\n",
    "\n",
    "y_pred = bnb.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total columns: 748.  Number of mislabeled columns: 320\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of total columns: {}.  Number of mislabeled columns: {}\".format(\n",
    "        data.shape[0],\n",
    "        (target != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[47, 315], [5, 381]]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TN = ((text['Rating'] == False) & (y_pred == False)).sum()\n",
    "FP = ((text['Rating'] == False) & (y_pred == True)).sum()\n",
    "FN = ((text['Rating'] == True) & (y_pred == False)).sum()\n",
    "TP = ((text['Rating'] == True) & (y_pred == True)).sum()\n",
    "\n",
    "matrix = [[TN, FP],\n",
    "           [FN, TP]]\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 47, 315],\n",
       "       [  5, 381]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(target, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Sensitivity is 98.70%. The Specificity is 12.98%.\n"
     ]
    }
   ],
   "source": [
    "# Percentage of positives correctly identified:\n",
    "sensitivity = (TP/(FN+TP))\n",
    "\n",
    "# Percentage of negatives correctly identified:\n",
    "specificity = (TN/(TN+FP))\n",
    "\n",
    "print(\"The Sensitivity is {:.2%}. The Specificity is {:.2%}.\".format(sensitivity, specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twenty Percent Holdout Score:0.5266666666666666\n"
     ]
    }
   ],
   "source": [
    "# With Holdout Testing:\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size = .2)\n",
    "print('Twenty Percent Holdout Score:' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55263158, 0.55263158, 0.54666667, 0.6       , 0.57333333,\n",
       "       0.57333333, 0.55405405, 0.58108108, 0.52702703, 0.60810811])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Validation testing:\n",
    "cross_val_score(bnb, data, target, cv = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was trying out both of the negatives and positives together, which got us one more correctly identified review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Classifier-4\"></a>\n",
    "### [Classifier 4](#Classifier-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_keys = ['great', 'incredible', 'like', 'liked', 'love', 'loved', 'awesome', 'I would recommend', 'I recommend',\n",
    "           'best', 'wonderful']\n",
    "neg_keys = ['I hated', 'I hate', 'bad', 'terrible', 'disgusting', 'boring', 'bore', 'waste', 'wasted',\n",
    "           'awful', 'slow', 'worse', 'worst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key in pos_keys:\n",
    "    text[str(key)] = text.Review.str.contains(\n",
    "    ' ' + str(key) + ' ',\n",
    "        case = False)\n",
    "    \n",
    "for key in neg_keys:\n",
    "    text[str(key)] = text.Review.str.contains(\n",
    "    ' ' + str(key) + ' ',\n",
    "        case = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = text[pos_keys + neg_keys]\n",
    "target = text['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bnb.fit(data, target)\n",
    "\n",
    "y_pred = bnb.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total columns: 748.  Number of mislabeled columns: 302\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of total columns: {}.  Number of mislabeled columns: {}\".format(\n",
    "        data.shape[0],\n",
    "        (target != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[64, 298], [4, 382]]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TN = ((text['Rating'] == False) & (y_pred == False)).sum()\n",
    "FP = ((text['Rating'] == False) & (y_pred == True)).sum()\n",
    "TP = ((text['Rating'] == True) & (y_pred == True)).sum()\n",
    "FN = ((text['Rating'] == True) & (y_pred == False)).sum()\n",
    "\n",
    "matrix = [[TN, FP],\n",
    "           [FN, TP]]\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 64, 298],\n",
       "       [  4, 382]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(target, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Sensitivity is 98.96%. The Specificity is 17.68%.\n"
     ]
    }
   ],
   "source": [
    "# Percentage of positives correctly identified:\n",
    "sensitivity = (TP/(FN+TP))\n",
    "\n",
    "# Percentage of negatives correctly identified:\n",
    "specificity = (TN/(TN+FP))\n",
    "\n",
    "print(\"The Sensitivity is {:.2%}. The Specificity is {:.2%}.\".format(sensitivity, specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twenty Percent Holdout Score0.6533333333333333\n"
     ]
    }
   ],
   "source": [
    "# Holdout Testing:\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size = .2)\n",
    "print('Twenty Percent Holdout Score' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51315789, 0.59210526, 0.54666667, 0.62666667, 0.62666667,\n",
       "       0.54666667, 0.58108108, 0.60810811, 0.54054054, 0.66216216])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Val testing:\n",
    "cross_val_score(bnb, data, target, cv = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Classifier-5\"></a>\n",
    "### [Classifier 5](#Classifier-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_keys = ['great', 'incredible', 'like', 'liked', 'love', 'loved', 'awesome', 'I would recommend', 'I recommend',\n",
    "           'best', 'wonderful', 'would', 'should']\n",
    "neg_keys = ['I hated', 'I hate', 'bad', 'terrible', 'disgusting', 'boring', 'bore', 'waste', 'wasted',\n",
    "           'awful', 'slow', 'worse', 'worst', 'cheesey', 'cheesy', 'raunchy', 'flaw', 'flawed', 'wouldn\\'t', \n",
    "           'don\\'t', 'shouldn\\'t', 'don\\'t go']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key in pos_keys:\n",
    "    text[str(key)] = text.Review.str.contains(\n",
    "    ' ' + str(key) + ' ',\n",
    "        case = False)\n",
    "    \n",
    "for key in neg_keys:\n",
    "    text[str(key)] = text.Review.str.contains(\n",
    "    ' ' + str(key) + ' ',\n",
    "        case = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = text[pos_keys + neg_keys]\n",
    "target = text['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bnb.fit(data, target)\n",
    "\n",
    "y_pred = bnb.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total columns: 748.  Number of mislabeled columns: 285\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of total columns: {}.  Number of mislabeled columns: {}\".format(\n",
    "        data.shape[0],\n",
    "        (target != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[92, 270], [15, 371]]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TN = ((text['Rating'] == False) & (y_pred == False)).sum()\n",
    "FP = ((text['Rating'] == False) & (y_pred == True)).sum()\n",
    "TP = ((text['Rating'] == True) & (y_pred == True)).sum()\n",
    "FN = ((text['Rating'] == True) & (y_pred == False)).sum()\n",
    "\n",
    "matrix = [[TN, FP],\n",
    "           [FN, TP]]\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 92, 270],\n",
       "       [ 15, 371]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(target, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Sensitivity is 96.11%. The Specificity is 25.41%.\n"
     ]
    }
   ],
   "source": [
    "# Percentage of positives correctly identified:\n",
    "sensitivity = (TP/(FN+TP))\n",
    "\n",
    "# Percentage of negatives correctly identified:\n",
    "specificity = (TN/(TN+FP))\n",
    "\n",
    "print(\"The Sensitivity is {:.2%}. The Specificity is {:.2%}.\".format(sensitivity, specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20% Holdout Score0.6333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Twenty Percent Holdout:\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size = .2)\n",
    "print('20% Holdout Score' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51315789, 0.60526316, 0.53333333, 0.64      , 0.64      ,\n",
       "       0.62666667, 0.59459459, 0.63513514, 0.56756757, 0.68918919])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross_val\n",
    "cross_val_score(bnb, data, target, cv = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Holdout-Groups\"></a>\n",
    "### [Holdout Groups](#Holdout-Groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_holdout = text[450:747]\n",
    "text_normal = text[0:449]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
